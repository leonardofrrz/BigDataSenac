# Tansformando tsv/csv em parquet com POLARS

import polars as pl
import os

# --- 1. ConfiguraÃ§Ã£o ---
BASE_PATH = r"C:/Users/leonardo.ferraz/Documents/Leonardo Ferraz/BigDataSenac/projetofinal"

FILES = [
    "title.basics.tsv",
    "title.ratings.tsv",
    "title.principals.tsv",
    "name.basics.tsv",
    "title.crew.tsv",
    "title.episode.tsv",
    "title.akas.tsv"
]

# --- 2. Loop por arquivo ---
for file_name in FILES:
    arquivo_tsv = os.path.join(BASE_PATH, file_name)
    arquivo_parquet = os.path.join(BASE_PATH, file_name.replace(".tsv", "_POLARS.parquet"))

    if not os.path.exists(arquivo_tsv):
        print(f"Arquivo nÃ£o encontrado: {arquivo_tsv}. Pulando...")
        continue

    print(f"\nConvertendo {arquivo_tsv} para {arquivo_parquet}...")

    try:
        # --- 3. Criar LazyFrame com tolerÃ¢ncia a erros ---
        lazy_df = pl.scan_csv(
            arquivo_tsv,
            separator="\t",
            null_values="\\N",
            encoding="utf8-lossy",
            quote_char=None,        # ignora aspas internas problemÃ¡ticas
            ignore_errors=True      # pula linhas com problemas de parsing
        )

        # --- 4. Salvar como Parquet ---
        lazy_df.sink_parquet(
            arquivo_parquet,
            compression="snappy"
        )

        print(f"Arquivo convertido com sucesso: {arquivo_parquet}")

    except Exception as e:
        print(f"Erro durante a conversÃ£o do arquivo {file_name}: {e}")


# 1ï¸âƒ£ O que Ã© um LazyFrame?

# Um LazyFrame Ã© uma representaÃ§Ã£o preguiÃ§osa de um dataframe.
# Diferente de um DataFrame normal, que carrega e processa os dados imediatamente, o LazyFrame sÃ³ guarda as instruÃ§Ãµes que vocÃª quer aplicar nos dados.
# Nenhum dado Ã© realmente carregado ou processado atÃ© que vocÃª execute uma aÃ§Ã£o de â€œsinkâ€ ou â€œcollectâ€.
# Em outras palavras: vocÃª descreve o que quer fazer, e sÃ³ no final o Polars executa tudo de uma vez, de forma otimizada.

# 2ï¸âƒ£ DiferenÃ§a entre DataFrame e LazyFrame

# Recurso	DataFrame	LazyFrame
# Carregamento	        Imediato	  PreguiÃ§oso (adiado)
# ExecuÃ§Ã£o de operaÃ§Ãµes	Imediata	  Executada somente no final
# OtimizaÃ§Ã£o	        Limitada	  Polars reorganiza e otimiza
# Uso tÃ­pico	   Pequenos datasets, testes    Grandes datasets, ETL, pipelines

# 3ï¸âƒ£ Exemplo simples

# import polars as pl

# # LazyFrame: apenas descreve operaÃ§Ãµes, nada Ã© carregado ainda
# lf = pl.scan_csv("title.basics.tsv", separator="\t", null_values="\\N")

# # Adiciona uma operaÃ§Ã£o de filtro
# lf = lf.filter(pl.col("startYear") > 2000)

# # Adiciona uma operaÃ§Ã£o de seleÃ§Ã£o de colunas
# lf = lf.select(["tconst", "primaryTitle", "startYear"])

# # Nessa etapa, ainda nÃ£o foi feito nada no arquivo real
# # Polars sÃ³ armazenou as instruÃ§Ãµes

# # SÃ³ aqui os dados sÃ£o carregados e processados de verdade
# df = lf.collect()  # df Ã© um DataFrame normal agora
# print(df.head())

# 4ï¸âƒ£ Por que usar LazyFrame?

# EficiÃªncia em grandes arquivos: Polars consegue otimizar mÃºltiplas operaÃ§Ãµes de uma vez (filtragem, agregaÃ§Ãµes, joins) sem precisar passar pelos dados vÃ¡rias vezes.
# Menos memÃ³ria: como os dados sÃ³ sÃ£o carregados quando necessÃ¡rio, vocÃª nÃ£o precisa armazenar tudo na memÃ³ria imediatamente.
# Bom para ETL: se vocÃª tiver pipelines de transformaÃ§Ã£o de dados complexos, LazyFrame permite que tudo seja planejado antes de executar.

#---------------------------------------------------------------------------------------------------------------------------------------------------------------------------

# 1ï¸âƒ£ collect()

# O que faz:
# Executa todas as operaÃ§Ãµes que vocÃª definiu no LazyFrame e retorna um DataFrame normal (eager) com os resultados.

# AtÃ© vocÃª chamar collect(), nenhuma leitura ou cÃ¡lculo real ocorre.

# Exemplo:

# import polars as pl

# # LazyFrame: carregamento preguiÃ§oso
# lf = pl.scan_csv("title.basics.tsv", sep="\t", null_values="\\N")

# # Adicionando algumas operaÃ§Ãµes
# lf = lf.filter(pl.col("startYear") > 2000).select(["tconst", "primaryTitle", "startYear"])

# # Nada foi processado ainda
# print(type(lf))  # <class 'polars.internals.lazyframe.LazyFrame'>

# # Aqui sim: os dados sÃ£o processados e retornados
# df = lf.collect()
# print(df.head())
# print(type(df))  # <class 'polars.internals.dataframe.DataFrame'>


# âœ… collect() = executar tudo e retornar os dados reais.

# 2ï¸âƒ£ explain()

# O que faz:
# Mostra o plano de execuÃ§Ã£o interno do LazyFrame, ou seja, como o Polars pretende executar suas operaÃ§Ãµes.

# Muito Ãºtil para debug, otimizaÃ§Ã£o e entender como Polars reordena operaÃ§Ãµes.

# NÃ£o carrega os dados reais, apenas mostra a lÃ³gica.

# Exemplo:

# # Exibe o plano lÃ³gico e fÃ­sico
# lf.explain()


# SaÃ­da tÃ­pica (simplificada):

# Logical Plan:
#   Scan CSV: title.basics.tsv
#   Filter: startYear > 2000
#   Projection: ["tconst", "primaryTitle", "startYear"]

# Physical Plan:
#   CSV Scan (optimized)
#   Filter pushdown applied
#   Projection pushdown applied


# ğŸ’¡ Aqui vocÃª vÃª que:

# O Polars otimiza a leitura, aplicando filtros e projeÃ§Ãµes antes de carregar os dados.

# Para arquivos grandes, isso economiza muita memÃ³ria e tempo.

# 3ï¸âƒ£ Fluxo resumido

# CriaÃ§Ã£o do LazyFrame â†’ define o pipeline preguiÃ§osamente

# DefiniÃ§Ã£o de transformaÃ§Ãµes â†’ filtros, seleÃ§Ãµes, joins, agregaÃ§Ãµes

# explain() â†’ ver como o Polars vai executar tudo

# collect() â†’ realmente executa o pipeline e retorna o DataFrame

# ğŸ’¡ Dica prÃ¡tica:

# Se vocÃª estiver processando arquivos gigantes (como os da IMDb), use scan_csv() + LazyFrame,
#  defina todos os filtros e seleÃ§Ãµes, rode explain() para conferir o plano e sÃ³ depois chame collect() ou sink_parquet(). Isso garante mÃ¡xima eficiÃªncia